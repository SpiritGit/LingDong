import speech_recognition as sr
import requests
import asyncio
import edge_tts
import os

# 1. è¯­éŸ³è½¬æ–‡å­— (STT)
def listen():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print("ğŸ¤ å¬å€™æŒ‡ä»¤ä¸­...")
        audio = r.listen(source)
    try:
        text = r.recognize_google(audio, language='zh-CN')
        print(f"ğŸ‘‚ æˆ‘å¬åˆ°äº†: {text}")
        return text
    except:
        return None

# 2. è°ƒç”¨ Ollama (LLM) - è¿åˆ°ä½ çš„ Spirit Pro
def ask_ollama(prompt):
    url = "http://100.88.159.2:11434/api/generate" # ä½ çš„ Spirit Pro IP
    payload = {"model": "deepseek-r1:7b", "prompt": prompt, "stream": False}
    try:
        response = requests.post(url, json=payload, timeout=30)
        return response.json().get("response")
    except Exception as e:
        return f"å¤§è„‘è¿æ¥å¤±è´¥: {e}"

# 3. æ–‡å­—è½¬è¯­éŸ³ (TTS)
async def speak(text):
    print(f"ğŸ¤– å°è½¦è¯´: {text}")
    communicate = edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural")
    await communicate.save("reply.mp3")
    os.system("mpg123 reply.mp3") # éœ€è¦ sudo apt install mpg123

async def main():
    while True:
        user_text = listen()
        if user_text:
            if "é€€å‡º" in user_text: break
            answer = ask_ollama(user_text)
            await speak(answer)

if __name__ == "__main__":
    asyncio.run(main())